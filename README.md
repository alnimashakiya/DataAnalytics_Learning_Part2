# DataAnalytics_Learning_Part2

# DATA ANALYTICS
Data analytics can be divided into several different stages, each with its own objectives and analytical approaches. Here is a brief explanation of each stage:

# 1. _Descriptive Analytics_
This is the initial stage of data analysis where data is understood, described, and summarized statistically. The primary goal is to provide a comprehensive understanding of patterns in the data without making inferences or predictions about the future. It involves the use of descriptive statistics, data visualization, and other techniques to present data in an understandable manner.

Here are examples of descriptive data in data analytics:

1. **Descriptive Statistics**: This includes measures of central tendency such as mean, median, and mode, as well as measures of dispersion such as range, standard deviation, and variance. Examples of descriptive statistics for a dataset of student heights may include the average height, median height, and mode height, as well as the standard deviation of height.

2. **Histogram**: A histogram is a visual representation of the frequency distribution of a variable. It divides the range of variable values into several intervals and shows the number of observations that fall into each interval. An example histogram in data analysis might display the frequency distribution of student test scores.

3. **Boxplot**: A boxplot is a visual diagram that displays a summary of the distribution of one or more numeric variables through boxes, lines, and points. It provides information about the median, quartiles, and the presence of outliers in the data. Examples of boxplots can be used to compare the salary distribution among departments in a company.

4. **Pie Chart**: A pie chart is a visual representation of the relative proportions of several categories within a whole. It is useful for showing the contribution of each category to the total. Examples of pie charts might display the sales proportions of various products in a year.

5. **Frequency Table**: A frequency table is a table that shows the number of observations or frequency for each value or category of one or more variables. It is useful for summarizing the distribution or pattern of data. Examples of frequency tables might display the number of students in each grade in a school.

These examples are some common ways in which descriptive data is used in data analytics to provide a better understanding of the characteristics and patterns within a dataset.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/4639fa04-4c99-41e7-bad4-ab2e34200e41)

# 2. _Diagnostic Analytics_
This stage involves using data to understand why something happened or to identify patterns, anomalies, or issues in the data that require further investigation or corrective action. It involves techniques such as correlation analysis, regression analysis, outlier detection, and anomaly analysis to understand relationships between variables, determine root causes, or identify issues in the data.

Diagnostic analytics involves analyzing data to understand why certain events or outcomes occurred. It aims to identify the root causes of problems or to uncover patterns that explain historical data trends. Here are some examples of diagnostic analytics:

1. **Root Cause Analysis**: Analyzing customer complaints to determine the underlying reasons for product defects or service issues. This involves investigating factors such as manufacturing processes, supplier quality, or employee training to identify the root causes of problems.

2. **Anomaly Detection**: Identifying unusual patterns or outliers in data that deviate from the norm. For example, detecting fraudulent transactions in financial data, unusual spikes in website traffic, or unexpected fluctuations in stock prices.

3. **Failure Analysis**: Investigating equipment failures or system breakdowns to understand the contributing factors. This may involve analyzing maintenance records, equipment performance data, and environmental conditions to determine the root causes of failures.

4. **Quality Control Analysis**: Examining production data to identify defects or variations in product quality. This could involve analyzing manufacturing process parameters, quality inspection results, and customer feedback to pinpoint areas for improvement.

5. **Customer Churn Analysis**: Investigating the reasons why customers leave a company's products or services. This may involve analyzing customer behavior, satisfaction surveys, and service interactions to identify factors contributing to customer churn.

6. **Healthcare Analytics**: Analyzing patient data to understand disease patterns, treatment effectiveness, and factors influencing patient outcomes. This could involve examining electronic health records, medical imaging data, and clinical trial results to improve healthcare decision-making.

7. **Supply Chain Analysis**: Investigating disruptions or delays in the supply chain to identify the root causes. This may involve analyzing inventory levels, transportation data, and supplier performance metrics to improve supply chain efficiency and resilience.

These examples illustrate how diagnostic analytics can be applied across various industries and domains to uncover insights and improve decision-making by understanding the reasons behind past events or outcomes.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/105374e5-2c85-4b61-bd6d-d6389c721471)

# 3. _Hypothesis Testing_
This stage involves forming and testing hypotheses to validate or reject certain assumptions or conjectures about the data. It is often used in experimental or scientific contexts to determine if there is sufficient evidence to support or reject specific hypotheses.

Hypothesis testing is a fundamental concept in data analytics that involves making inferences about a population based on sample data. Here are some examples of hypothesis testing in data analytics:

1. **A/B Testing in Marketing**: A company wants to compare the effectiveness of two different versions of an email marketing campaign. They randomly divide their email subscribers into two groups: Group A receives the original version of the email, while Group B receives a modified version with a different subject line. After sending out the emails, the company measures the click-through rates for each group. Hypothesis testing can be used to determine whether the difference in click-through rates between the two groups is statistically significant.

2. **Drug Efficacy in Healthcare**: A pharmaceutical company develops a new drug intended to lower cholesterol levels in patients. To assess its efficacy, the company conducts a randomized controlled trial where patients are randomly assigned to receive either the new drug or a placebo. After a certain period, the cholesterol levels of the two groups are compared. Hypothesis testing can be used to determine whether there is a statistically significant difference in cholesterol levels between the two groups, indicating the effectiveness of the new drug.

3. **Employee Satisfaction in Human Resources**: A company wants to investigate whether there is a difference in job satisfaction between employees in different departments. They administer a survey to employees from various departments and collect data on job satisfaction levels. Hypothesis testing can be used to compare the mean job satisfaction scores between different departments and determine whether any observed differences are statistically significant.

4. **Customer Behavior in E-commerce**: An e-commerce company wants to determine whether offering free shipping affects customer purchase behavior. They randomly select a group of customers to receive free shipping on their orders, while another group pays standard shipping fees. After a certain period, the company analyzes the purchase behavior of both groups. Hypothesis testing can be used to assess whether there is a statistically significant difference in purchase frequency or order value between the two groups.

5. **Weather Patterns in Environmental Science**: A meteorologist wants to investigate whether there has been a significant change in average temperatures over the past decade. They collect temperature data from weather stations for the past ten years and analyze the data to detect any trends. Hypothesis testing can be used to determine whether there is sufficient evidence to conclude that there has been a statistically significant change in average temperatures over time.

These examples demonstrate how hypothesis testing is used in various domains of data analytics to make evidence-based decisions and draw conclusions from data.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/e311200a-d50b-4465-a605-b960d757281d)

# 4. _Predictive Analytics_
This is the stage where data is used to make predictions about future outcomes based on historical patterns or trends in the data. It involves the use of statistical techniques such as regression analysis, predictive modeling, and machine learning to forecast future values or to identify patterns that may emerge in the future.

Predictive analytics involves using historical data to make predictions about future events or outcomes. Here are some examples of predictive analytics in data analytics:

1. **Customer Churn Prediction**: A telecommunications company wants to predict which customers are likely to churn (cancel their service) in the next month. They can use historical customer data such as usage patterns, demographics, and customer service interactions to train a machine learning model. This model can then be used to predict the likelihood of churn for each customer in the future, allowing the company to take proactive retention actions.

2. **Sales Forecasting**: A retail company wants to forecast sales for the next quarter to optimize inventory management and staffing. They can analyze historical sales data along with external factors such as seasonality, economic indicators, and marketing campaigns to build a predictive model. This model can then be used to predict future sales volumes, enabling the company to adjust inventory levels and staffing accordingly.

3. **Credit Risk Assessment**: A financial institution wants to assess the credit risk of loan applicants to make lending decisions. They can use historical loan data along with applicant information such as credit score, income, and employment history to train a predictive model. This model can then be used to predict the likelihood of default for each loan applicant, helping the institution make informed lending decisions.

4. **Demand Forecasting**: A manufacturing company wants to forecast demand for its products to optimize production planning and supply chain management. They can analyze historical sales data along with factors such as market trends, seasonality, and promotional activities to build a predictive model. This model can then be used to predict future demand for each product, allowing the company to adjust production levels and inventory accordingly.

5. **Healthcare Outcome Prediction**: A hospital wants to predict patient outcomes such as readmission rates or complications following surgery. They can analyze electronic health records, lab results, and patient demographics to build predictive models. These models can then be used to predict the likelihood of adverse outcomes for each patient, allowing the hospital to intervene early and improve patient care.

These examples demonstrate how predictive analytics can be applied across various industries and domains to make predictions about future events or outcomes using historical data and machine learning techniques.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/46555650-8fc6-4c86-bb5f-dfc4dd041638)

# 5. _Prescriptive Analytics_
This stage involves using data to provide recommendations or actions needed to achieve specific goals or to optimize outcomes. It involves the use of mathematical models, optimization, and scenario analysis to determine the best course of action based on available information.

Prescriptive analytics involves using data-driven insights to recommend actions or decisions that optimize outcomes or achieve specific business objectives. Here are some examples of prescriptive analytics in data analytics:

1. **Dynamic Pricing Optimization**: An e-commerce company wants to optimize pricing strategies for its products to maximize revenue. By analyzing historical sales data, competitor pricing, customer demographics, and market trends, they can build a prescriptive analytics model. This model can recommend dynamic pricing adjustments in real-time based on factors such as demand elasticity, inventory levels, and customer segmentation to maximize profitability.

2. **Supply Chain Optimization**: A logistics company wants to optimize its supply chain operations to minimize costs and improve efficiency. By analyzing historical shipment data, transportation routes, inventory levels, and supplier performance, they can build a prescriptive analytics model. This model can recommend optimal routes, transportation modes, and inventory levels to minimize transportation costs, reduce lead times, and improve overall supply chain performance.

3. **Personalized Healthcare Treatment Plans**: A healthcare provider wants to optimize treatment plans for patients with chronic diseases such as diabetes or heart disease. By analyzing electronic health records, medical history, genetic data, and treatment outcomes, they can build a prescriptive analytics model. This model can recommend personalized treatment plans, medication dosages, and lifestyle interventions tailored to each patient's unique characteristics and health goals to optimize health outcomes and reduce healthcare costs.

4. **Credit Risk Mitigation Strategies**: A financial institution wants to mitigate credit risk and minimize loan defaults. By analyzing historical loan data, credit scores, income levels, and economic indicators, they can build a prescriptive analytics model. This model can recommend risk mitigation strategies such as loan restructuring, collateral requirements, or credit limit adjustments for high-risk borrowers to minimize default rates and maximize profitability.

5. **Energy Consumption Optimization**: A utility company wants to optimize energy consumption and reduce costs for its customers. By analyzing historical energy usage data, weather patterns, building characteristics, and energy prices, they can build a prescriptive analytics model. This model can recommend energy-efficient technologies, demand response programs, and pricing plans tailored to each customer's usage patterns and preferences to reduce energy consumption and lower utility bills.

These examples illustrate how prescriptive analytics can be applied across various industries and domains to recommend optimal actions or decisions that drive business value and improve outcomes.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/356e2d9a-b11d-4677-b9a9-8a4f943efa3f)

# ROOT CAUSES

"Root causes" are the fundamental factors or origins that lead to an event or issue. Identifying root causes is crucial for effectively addressing problems and preventing the recurrence of the same issues in the future.

And **SOLUTION** become actions or steps designed to address or overcome the root causes of an issue or event.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/42b55c4c-f84e-4e82-985e-a64cf988bc45)

# DATA STORYTELLING
Data storytelling in data analytics is the process of presenting data analysis and insights in a narrative format using the Python programming language and its libraries. It involves steps such as data preparation, exploratory data analysis, visualization, as well as communicating the analysis results to stakeholders. The goal is to transform data analysis findings into a compelling story that is engaging and easily understood, thus providing valuable insights and supporting decision-making.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/06dd8a31-6b73-47e7-9f82-e7fa297164d4)

# CORRELATION
Correlation in data analysis is a statistical measure used to evaluate the relationship or dependency between two or more variables. It assesses the strength and direction of the relationship between these variables. In the context of data analysis, correlation aids in understanding patterns and interactions among the observed variables.

Correlation is expressed on a scale ranging from -1 to 1, where:

- A correlation value of +1 indicates a perfect positive linear relationship between the variables. This means that when one variable increases, the other also increases, and vice versa.
- A correlation value of -1 indicates a perfect negative linear relationship between the variables. This implies that when one variable increases, the other decreases, and vice versa.
- A correlation value of 0 indicates no linear relationship between the variables.

Furthermore, correlation values can be interpreted as follows:

- Values close to +1 or -1 indicate strong relationships between the variables.
- Values close to 0 indicate weak relationships between the variables.

Correlation aids in data analysis by identifying hidden patterns, determining influential variables, and understanding how variables interact with each other. It is a crucial tool in understanding the data structure and making decisions based on the information obtained from the data.

![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/e52038c9-1142-4416-b590-3d1d545c3d5c)

# ANOMLY
Events that exceed the threshold value are called extreme events. Modeling extreme events cannot be done with a normal distribution approach, but with a distribution that has a long tail (heavy tail).
![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/3767b06c-7dfb-4d2e-9a19-5b204d4e40c0)

# OUTLIER
In statistics, an outlier is a data point that differs significantly from other observations. Outliers may be caused by variability in measurements, indicative of new data or may be the result of experimental error
![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/e18448c7-c87d-45f4-8993-8a1b4217f5d7)

# PAIRED T-TEST
T-tests are statistical tools used to compare the means of two groups. There are several types of t-tests, with the most common ones being:
Independent T-Test: Used when you want to compare the means of two different groups independently. For example, you might want to know if there's a difference in test scores between male and female students.
![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/4c4c8e63-012b-4ed9-9ab8-087dfb12f05d)

# REGRESSION ANALYTICS
Regression analysis is a statistical technique used in data analytics to understand the relationship between a dependent variable (target) and one or more independent variables (features). It helps in predicting the value of the dependent variable based on the values of independent variables.
![image](https://github.com/alnimashakiya/DataAnalytics_Learning_Part2/assets/165742697/eb8616f4-e0a5-429d-b932-cbc40f9dfe32)

# DEFINE AND DESCRIBE THE ROLE ARTIFICIAL INTELLIGENCE (AI) IN DATA ANALYST
Artificial intelligence (AI) in data analysis refers to the use of advanced computational techniques to process and analyze large and complex datasets. AI algorithms and technologies enable computers to mimic human-like intelligence, learning from data, recognizing patterns, making predictions, and generating insights without explicit programming.

